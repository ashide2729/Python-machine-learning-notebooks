{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first component of speech recognition is, of course, speech. Speech must be converted from physical sound to an electrical signal with a microphone, and then to digital data with an analog-to-digital converter. Once digitized, several models can be used to transcribe the audio to text.\n",
    "\n",
    "Most modern speech recognition systems rely on what is known as a Hidden Markov Model (HMM). This approach works on the assumption that a speech signal, when viewed on a short enough timescale (say, ten milliseconds), can be reasonably approximated as a stationary process—that is, a process in which statistical properties do not change over time.\n",
    "\n",
    "In a typical HMM, the speech signal is divided into 10-millisecond fragments. The power spectrum of each fragment, which is essentially a plot of the signal’s power as a function of frequency, is mapped to a vector of real numbers known as cepstral coefficients. The dimension of this vector is usually small—sometimes as low as 10, although more accurate systems may have dimension 32 or more. The final output of the HMM is a sequence of these vectors.\n",
    "\n",
    "To decode the speech into text, groups of vectors are matched to one or more phonemes—a fundamental unit of speech. This calculation requires training, since the sound of a phoneme varies from speaker to speaker, and even varies from one utterance to another by the same speaker. A special algorithm is then applied to determine the most likely word (or words) that produce the given sequence of phonemes.\n",
    "\n",
    "One can imagine that this whole process may be computationally expensive. In many modern speech recognition systems, neural networks are used to simplify the speech signal using techniques for feature transformation and dimensionality reduction before HMM recognition. Voice activity detectors (VADs) are also used to reduce an audio signal to only the portions that are likely to contain speech. This prevents the recognizer from wasting time analyzing unnecessary parts of the signal.\n",
    "\n",
    "Fortunately, as a Python programmer, you don’t have to worry about any of this. A number of speech recognition services are available for use online through an API, and many of these services offer Python SDKs.\n",
    "\n",
    "A handful of packages for speech recognition exist on PyPI. A few of them include:\n",
    "\n",
    "- apiai\n",
    "- assemblyai\n",
    "- google-cloud-speech\n",
    "- pocketsphinx\n",
    "- SpeechRecognition\n",
    "- watson-developer-cloud\n",
    "- wit\n",
    "\n",
    "To install speech recognition library use \"!pip install SpeechRecognition\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the library and let's get started  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert audio file to text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file said: \n",
      " summary the sites to break a teacher for the you keep error code coverage work for places to save money baby is taking longer to getting squared away then the bank is expected in the life event company in AVN had Tak Sahi retirement income the top news of the saving ragnarok latest update you naked Bond what a discussion can insert when the title of this type of song is in question or waxing or gasing needed I provide 90% discount by workplace leather lace work on a flat surface and smooth out this time system uses its angles of intent Unity asset store holds a good mechanical isliye bad boss 12 figures with Gauhar in lete Samay beautiful chairs cabinets test for houses\n",
      "This is said in first 10 seconds: \n",
      " summary the sites to break a teacher for the you keep adequate coverage work for places to save money baby is taking longer to getting squared away\n",
      "This is said in first 10 seconds: \n",
      " summary the sites to break a teacher for the you keep adequate coverage work for places to save money baby is taking longer to getting squared away\n",
      "This is said in next 10 seconds: \n",
      " is expected in the wife Reliance company Mai when hurt accident vitamin encounter 200 top news of saving drugs\n",
      "This is said after skipping first 10 seconds: \n",
      " bankers expected during the wife event company in AVN had accepted vitamin encounter 200 top news of saving drugs\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "    \n",
    "audio_file = sr.AudioFile('male.wav')    \n",
    "with audio_file as source:\n",
    "    audio1 = r.record(source)\n",
    "\n",
    "google = r.recognize_google(audio1)        # Google Web Speech API\n",
    "\n",
    "print(\"The file said:\", '\\n', google)\n",
    "\n",
    "# To reduce the duration of hearing from file add duration variable in record\n",
    "with audio_file as source:\n",
    "    audio1 = r.record(source, duration=10)\n",
    "\n",
    "google = r.recognize_google(audio1)        \n",
    "\n",
    "print(\"This is said in first 10 seconds:\", '\\n', google)\n",
    "\n",
    "# To read from file in segments  \n",
    "with audio_file as source:\n",
    "    audio1 = r.record(source, duration=10)\n",
    "    audio2 = r.record(source, duration=10)\n",
    "google = r.recognize_google(audio1)\n",
    "google2 = r.recognize_google(audio2)\n",
    "\n",
    "print(\"This is said in first 10 seconds:\", '\\n', google)\n",
    "print(\"This is said in next 10 seconds:\", '\\n', google2)\n",
    "\n",
    "# To skip a part of the audio file we use offset\n",
    "with audio_file as source:\n",
    "    audio1 = r.record(source, offset=10, duration=10)\n",
    "\n",
    "google = r.recognize_google(audio1)        \n",
    "\n",
    "print(\"This is said after skipping first 10 seconds:\", '\\n', google)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with noisy data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is said after noise reduction: \n",
      " is expected in the wife Reliance company Mai when hurt accident vitamin encounter 200 top news of saving drugs\n",
      "This is said after noise reduction: \n",
      " bankers expected during the wife event company in AVN had accepted vitamin encounter 200 top news of saving drugs\n"
     ]
    }
   ],
   "source": [
    "# To remove the noise from audio \n",
    "with audio_file as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio1 = r.record(source, offset=10, duration=10)\n",
    "\n",
    "google = r.recognize_google(audio1)        \n",
    "\n",
    "print(\"This is said after noise reduction:\", '\\n', google)\n",
    "\n",
    "# To adjust the calibration time taken by the method so that we don't skip the information\n",
    "with audio_file as source:\n",
    "    r.adjust_for_ambient_noise(source, duration=0.5) # This defines the time the adjuster waits for calibration to avoid missing words\n",
    "    audio1 = r.record(source, offset=10, duration=10)\n",
    "\n",
    "google = r.recognize_google(audio1)        \n",
    "\n",
    "print(\"This is said after noise reduction:\", '\\n', google)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the possible outputs \n",
      " {'alternative': [{'transcript': 'places to save money is taking longer to getting squared', 'confidence': 0.70617819}, {'transcript': 'places to sleep my baby is taking longer to getting squared'}, {'transcript': 'places to save money is taking longer to getting scared'}, {'transcript': 'places to sleep my baby is taking longer to getting scared'}, {'transcript': 'places to save money is taking longer to getting square'}], 'final': True}\n"
     ]
    }
   ],
   "source": [
    "with audio_file as source:\n",
    "    audio1 = r.record(source, offset=5, duration=5)\n",
    "\n",
    "google = r.recognize_google(audio1, show_all=True)\n",
    "\n",
    "print(\"These are the possible outputs\", '\\n', google)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with audio inputs from microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pyaudio library is used by speech recognition library to take input from microphone\n",
    "# !pip install pipwin\n",
    "# !pipwin install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft Sound Mapper - Input',\n",
       " 'Microphone Array (Realtek(R) Au',\n",
       " 'Microsoft Sound Mapper - Output',\n",
       " 'Speaker/Headphone (Realtek(R) A',\n",
       " 'Primary Sound Capture Driver',\n",
       " 'Microphone Array (Realtek(R) Audio)',\n",
       " 'Primary Sound Driver',\n",
       " 'Speaker/Headphone (Realtek(R) Audio)',\n",
       " 'Speaker/Headphone (Realtek(R) Audio)',\n",
       " 'Microphone Array (Realtek(R) Audio)',\n",
       " 'Speakers (Realtek HD Audio output)',\n",
       " 'Microphone Array 1 (Realtek HD Audio Mic input with SST)',\n",
       " 'Microphone Array 2 (Realtek HD Audio Mic input with SST)',\n",
       " 'Microphone Array 3 (Realtek HD Audio Mic input with SST)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You said:  1234 exclamation @ hash\n"
     ]
    }
   ],
   "source": [
    "# Here the listen method is used instead of record incase of mic audio input\n",
    "with sr.Microphone() as source:\n",
    "    audio1 = r.listen(source)\n",
    "    \n",
    "print(\"You said: \", r.recognize_google(audio1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
